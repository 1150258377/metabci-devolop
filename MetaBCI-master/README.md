# MetaBCI

## Welcome! 
MetaBCI is an open-source platform for non-invasive brain computer interface. The project of MetaBCI is led by Prof. Minpeng Xu from Tianjin University, China. MetaBCI has 3 main parts:
* brainda: for importing dataset, pre-processing EEG data and implementing EEG decoding algorithms.
* brainflow: a high speed EEG online data processing framework.
* brainstim: a simple and efficient BCI experiment paradigms design module. 

This is the first release of MetaBCI, our team will continue to maintain the repository. If you need the handbook of this repository, please contact us by sending email to TBC_TJU_2022@163.com with the following information:
* Name of your teamleader
* Name of your university(or organization)

We will send you a copy of the handbook as soon as we receive your information.

## Paper

If you find MetaBCI useful in your research, please cite:

Mei, J., Luo, R., Xu, L., Zhao, W., Wen, S., Wang, K., ... & Ming, D. (2023). MetaBCI: An open-source platform for brain-computer interfaces. Computers in Biology and Medicine, 107806.

And this open access paper can be found here: [MetaBCI](https://www.sciencedirect.com/science/article/pii/S0010482523012714)

## Content

- [MetaBCI](#metabci)
  - [Welcome!](#welcome)
  - [Paper](#paper)
  - [What are we doing?](#what-are-we-doing)
    - [The problem](#the-problem)
    - [The solution](#the-solution)
  - [Features](#features)
  - [Installation](#installation)
  - [Who are we?](#who-are-we)
  - [What do we need?](#what-do-we-need)
  - [Contributing](#contributing)
  - [License](#license)
  - [Contact](#contact)
  - [Acknowledgements](#acknowledgements)

## What are we doing?

### The problem

* BCI datasets come in different formats and standards
* It's tedious to figure out the details of the data
* Lack of python implementations of modern decoding algorithms
* It's not an easy thing to perform BCI experiments especially for the online ones.

If someone new to the BCI wants to do some interesting research, most of their time would be spent on preprocessing the data, reproducing the algorithm in the paper, and also find it difficult to bring the algorithms into BCI experiments.

### The solution

The Meta-BCI will:

* Allow users to load the data easily without knowing the details
* Provide flexible hook functions to control the preprocessing flow
* Provide the latest decoding algorithms
* Provide the experiment UI for different paradigms (e.g. MI, P300 and SSVEP)
* Provide the online data acquiring pipeline.
* Allow users to bring their pre-trained models to the online decoding pipeline.

The goal of the Meta-BCI is to make researchers focus on improving their own BCI algorithms and performing their experiments without wasting too much time on preliminary preparations.

## Features

* Improvements to MOABB APIs
   - add hook functions to control the preprocessing flow more easily
   - use joblib to accelerate the data loading
   - add proxy options for network connection issues
   - add more information in the meta of data
   - other small changes

* Supported Datasets
   - MI Datasets
     - AlexMI
     - BNCI2014001, BNCI2014004
     - PhysionetMI, PhysionetME
     - Cho2017
     - MunichMI
     - Schirrmeister2017
     - Weibo2014
     - Zhou2016
   - SSVEP Datasets
     - Nakanishi2015
     - Wang2016
     - BETA

* Implemented BCI algorithms
   - Decomposition Methods
     - SPoC, CSP, MultiCSP and FBCSP
     - CCA, itCCA, MsCCA, ExtendCCA, ttCCA, MsetCCA, MsetCCA-R, TRCA, TRCA-R, SSCOR and TDCA
     - DSP
   - Manifold Learning
     - Basic Riemannian Geometry operations
     - Alignment methods
     - Riemann Procustes Analysis
   - Deep Learning
     - ShallowConvNet
     - EEGNet
     - ConvCA
     - GuneyNet
     - Cross dataset transfer learning based on pre-training
   - Transfer Learning
     - MEKT
     - LST

## DREAMER Emotion Recognition Demo (New)

This release integrates the DREAMER emotion-recognition dataset into MetaBCI.  
You can now load the raw DREAMER `.mat` file and quickly evaluate a simple EEG-based
emotion-classification pipeline that extracts frequencyâ€“band power features and
trains an SVM.

### 1  Prerequisites

```bash
# basic dependencies (already listed in requirements.txt)
pip install mne scikit-learn scipy mat73
```

### 2  Dataset placement

Download `DREAMER.mat` from the official website and copy / move it to the root of
the repository (the same folder that contains `README.md`). The demo searches this
exact path and therefore requires no extra arguments.

### 3  Run the demo

```bash
# from the project root
python MetaBCI-master/demos/dreamer_analysis.py
```

The script will

1. Load EEG for the specified subject (default **1**)
2. Band-pass filter (1â€“45 Hz)
3. Compute band-power features (Î¸, Î±, Î², Î³) using the new helper
   `metabci.brainda.algorithms.feature_analysis.bandpower`
4. Train an RBF-kernel SVM and print an accuracy / classification report.

Feel free to edit `subject_id`, change frequency bands or swap the classifier to
explore the dataset.

### 4  Code changes behind the scenes

* **metabci/brainda/datasets/dreamer.py** â€“ new robust loader supporting both
  `scipy.io` & `mat73` structures.
* **datasets/__init__.py** â€“ cleaned invalid imports that previously caused
  `ImportError`.
* **algorithms/feature_analysis/freq_analysis.py** â€“ added `bandpower` and
  re-exported it via `feature_analysis.__init__`.
* **demos/dreamer_analysis.py** â€“ end-to-end example described above.

These edits have no impact on existing MI / P300 / SSVEP pipelines.

### 5  How to run & tweak

* **Run out-of-the-box**
  ```bash
  python MetaBCI-master/demos/dreamer_analysis.py
  ```
  The script loads data, extracts band-power features and trains an RBF-SVM.

* **Change the classifier**  â€“ open the same file and locate
  ```python
  clf = SVC(kernel='rbf', random_state=42)
  clf.fit(X_train, y_train)
  ```
  Replace the estimator with any classifier from `scikit-learn`, or plug in your
  own deep-learning model.

* **Labels** â€“ by default we do binary Valence classification (score > 3 â†’ 1,
  else 0). Edit the `label` line (~44) to create multi-class labels or switch to
  Arousal / Dominance.

* **Pipeline recap**
  1. Load one subject via `DREAMER` loader.
  2. 1â€“45 Hz band-pass filter.
  3. Compute Î¸/Î±/Î²/Î³ band power for every channel.
  4. Train classifier & evaluate.

---

Enjoy exploring emotion-related EEG with MetaBCI ğŸ‰

## Interactive EEG Playground (Streamlit)

`demos/eeg_platform_streamlit.py` æä¾›äº†ä¸€ä¸ªã€Œ**å‚»ç“œå¼**ã€çš„å¯è§†åŒ–å®éªŒå¹³å°ï¼Œå¯ä¸€é”®åˆ‡æ¢ **éšæœºæ¨¡æ‹Ÿä¿¡å·** ä¸ **DREAMER çœŸå®æ•°æ®**ï¼Œå¹¶åœ¨æµè§ˆå™¨ä¸­å³æ—¶æŸ¥çœ‹æ³¢å½¢ã€PSDã€ç‰¹å¾ä¸ MLP è®­ç»ƒè¿‡ç¨‹ã€‚

### 1  çœŸå®æ•°æ®è¯»å–

1. å‹¾é€‰ä¾§è¾¹æ  `ä½¿ç”¨ DREAMER æ•°æ®é›†` é€‰é¡¹ã€‚
2. é€‰æ‹©è¢«è¯•ç¼–å· *(1â€“23)*ã€æ ‡ç­¾ç»´åº¦ *(valence / arousal / dominance)* ä»¥åŠé«˜/ä½é˜ˆå€¼ *(é»˜è®¤ 3.0)*ã€‚
3. ä»£ç ç‰‡æ®µ
   ```python
   dreamer = DREAMER(subjects=[subj_id])
   subj_data = dreamer._get_single_subject_data(subj_id)
   raws = [d["run_1"] for d in subj_data.values()]   # 18 è§†é¢‘æ®µ
   raw_concat = mne.concatenate_raws(raws)            # -> (n_ch, n_time)
   data_raw = raw_concat.get_data()
   labels_per_vid = [1 if float(r.annotations.description[0])>thr else 0
                     for r in raws]
   ```
   *åŸå§‹ç»“æ„*ï¼š23 åè¢«è¯• Ã— 18 æ®µè§†é¢‘ï¼Œæ¯æ®µé™„å¸¦ 3 ç»´è¿ç»­è¯„åˆ† (1â€“5)ã€‚
   *å½“å‰ç®€åŒ–*ï¼šå¯¹é€‰å®šç»´åº¦äºŒå€¼åŒ– (score>é˜ˆå€¼ â†’ 1ï¼Œé«˜æƒ…ç»ª)ã€‚

### 2  é¢„å¤„ç† â†’ ç‰¹å¾ â†’ æ»‘çª— â†’ æ ‡ç­¾å¯¹é½

1. **å¸¦é€šæ»¤æ³¢**ï¼šç”¨æˆ·è‡ªå®šä¹‰ 
   ```python
   data_proc = bandpass_filter(data_raw, fs, l_freq, h_freq)
   ```
2. **(å¯é€‰) ç§¯åˆ†**ï¼š`np.cumsum` ä½œç§¯åˆ†ç‰¹å¾ã€‚  
3. **æ»‘åŠ¨çª—å£**ï¼š
   ```python
   win_len = int(fs * win_sec)    # çª—å£é•¿åº¦
   hop_len = int(fs * hop_sec)    # æ­¥é•¿
   for start in range(0, n_time-win_len+1, hop_len):
       seg = data_proc_sel[:, start:start+win_len]
   ```
4. **æ ‡ç­¾æ˜ å°„**ï¼šçª—å£èµ·ç‚¹å®šä½åˆ°æ‰€å±è§†é¢‘æ®µ
   ```python
   vid_idx = next(i for i,(s,e) in boundaries if s<=start<e)
   y.append(labels_per_vid[vid_idx])
   ```
   è¿™æ ·å³ä½¿ **æ—¶é—´è¢«é‡æ–°åˆ‡ç‰‡**ï¼Œä»ä¿æŒ *window â†” åŸè§†é¢‘æ ‡ç­¾* çš„ 1-to-1 å¯¹åº”ã€‚

### 3  ç‰¹å¾æ§½ (å¯è‡ªå®šä¹‰ 1â€“12 ç»´)

- ç±»å‹ï¼š`Raw`, `Filtered`, `Integrated`, `PSD`, `Bandpower`, ä»¥åŠ Î¸ / Î± / Î² / Î³ å››æ¡£åŠŸç‡ã€‚
- æ¯æ§½ = (é€šé“, ç‰¹å¾ç±»å‹)ã€‚ç•Œé¢æ‹–åŠ¨å³å¯æ·»åŠ /åˆ é™¤ã€‚
- `in_dim = len(slot_cfg)` è‡ªåŠ¨é€‚é…ç½‘ç»œè¾“å…¥ã€‚

### 4  MLP è®­ç»ƒ & è¯„ä¼°

- äºŒå±‚ MLPï¼Œéšè—å±‚å¤§å°å¯è°ƒï¼Œè®­ç»ƒè½®æ•°ä¸Šé™ 1000ã€‚
- è‡ªåŠ¨åˆ†å±‚ `train_test_split`ï¼ˆä¸è¶³æ—¶é™çº§åˆ°éšæœºåˆ’åˆ†ï¼‰ã€‚
- å®æ—¶ç»˜åˆ¶ Loss æ›²çº¿ + Test Accuracy + å•æ ·æœ¬æ¦‚ç‡ã€‚

### 5  ä»£ç ç¾è§‚ & é€»è¾‘é¡ºåº

```
â”Œ Sidebar (å‚æ•°ä¸ç‰¹å¾é…ç½®)
â”‚
â”œâ”€â”€ æ•°æ®æºé€‰æ‹© (éšæœº / DREAMER)
â”œâ”€â”€ é‡‡æ · & é¢„å¤„ç†å‚æ•°
â”œâ”€â”€ ç‰¹å¾æ§½ (åŠ¨æ€æ•°é‡)
â””â”€â”€ è®­ç»ƒå‚æ•°

â”Œ Tabs
â”‚
â”œâ”€â”€ ä¿¡å·å¯è§†åŒ– (Raw / Processed / PSD)
â””â”€â”€ MLP å¯è§†åŒ– (Graphviz ç»“æ„ + è®­ç»ƒæ›²çº¿ + Metric)
```
- æ¨¡å—åŒ–å‡½æ•° (`bandpass_filter`, `extract_scalar`, `build_features`) ä¿æŒä¸»æµç¨‹æ¸…æ™°ã€‚
- æ‰€æœ‰å¯è°ƒå‚æ•°å®æ—¶ç”Ÿæ•ˆï¼Œæ— éœ€é‡å¯ã€‚
- å…³é”®å¼‚å¸¸ï¼ˆå¦‚åˆ†å±‚é”™è¯¯ï¼‰è‡ªåŠ¨é™çº§å¹¶åœ¨ç•Œé¢æç¤º `st.warning`ã€‚

> **å°ç»“**ï¼šè„šæœ¬å®Œæ•´å¤ç”¨äº† <u>çœŸå®æƒ…ç»ªæ ‡ç­¾</u>ï¼Œåœ¨æ»‘çª—åä»ç²¾ç¡®æ˜ å°„ï¼›ç”¨æˆ·å¯è‡ªç”±å¢åˆ ç‰¹å¾æ§½ã€è°ƒæ•´çª—å£ä¸ç½‘ç»œç»“æ„ï¼Œå³åˆ»çœ‹åˆ°å¯¹åˆ†ç±»æ€§èƒ½çš„å½±å“ã€‚

---

## Installation

1. Clone the repo
   ```sh
   git clone https://github.com/TBC-TJU/MetaBCI.git
   ```
2. Change to the project directory
   ```sh
   cd MetaBCI
   ```
3. Install all requirements
   ```sh
   pip install -r requirements.txt 
   ```
4. Install brainda package with the editable mode
   ```sh
   pip install -e .
   ```
## Who are we?

The MetaBCI project is carried out by researchers from 
- Academy of Medical Engineering and Translational Medicine, Tianjin University, China
- Tianjin Brain Center, China


## What do we need?

**You**! In whatever way you can help.

We need expertise in programming, user experience, software sustainability, documentation and technical writing and project management.

We'd love your feedback along the way.

## Contributing

Contributions are what make the open source community such an amazing place to be learn, inspire, and create. **Any contributions you make are greatly appreciated**. Especially welcome to submit BCI algorithms.

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## License

Distributed under the GNU General Public License v2.0 License. See `LICENSE` for more information.

## Contact

Email: TBC_TJU_2022@163.com

## Acknowledgements
- [MNE](https://github.com/mne-tools/mne-python)
- [MOABB](https://github.com/NeuroTechX/moabb)
- [pyRiemann](https://github.com/alexandrebarachant/pyRiemann)
- [TRCA/eTRCA](https://github.com/mnakanishi/TRCA-SSVEP)
- [EEGNet](https://github.com/vlawhern/arl-eegmodels)
- [RPA](https://github.com/plcrodrigues/RPA)
- [MEKT](https://github.com/chamwen/MEKT)
